Lexer:
Esta parte del código, tiene que recorrer cada comando introducido en el loop.
Para cada llamada inicializa la estructura del lexer, copiando el input para no modificar el original.

Mientras recorre, clasifica con tokinicer, segun la siguiente estructura:

typedef enum e_token_type
{
	T_WORD,
	T_PIPE,
	T_REDIR_IN,
	T_REDIR_OUT,
	T_REDIR_APPEND,
	T_HEREDOC,
	T_QUOTE,
	T_SQUOTE,
	T_ERROR,
	T_EOF
}	t_token_type;

Lo mas importante en la función es la jerarquía:

1-Primeo comprueba espacios, y los salta.
2-Despues vienen las comillas, donde clasificara, dobles o simples.
3-Sigue con los operadores lógicos que vengan dobles "<<" "||" etc ...
4-Los operadores lógicos simples "&" "<" ";"
5-Sigue con las palabras o comandos.
6-Añade un token EOF, simplemente como marcador, para en proximas funciones recorrer hasta encontrar EOF.

Es importante destacar, que en el lexer no se detectan errores, pero si los clasifica.
"||" es clasificado como token "T_ERROR", se detectara mas adelante.
Si un comando no existe, lo detectera el ejecutor.

Al detectar comilla, comprueba si es simple o doble, busca la comilla de cierre,
si no existe, clasifica como error, si existe, crea un token copiando el valor entrecomillado
en token de dobles o el token de simples.

Detecta los operadores dobles comprobando el caracter e inmediatamente el siguiente.
Lo mismo ocurre con los operados simples.

Con las palabras es similar, detecta que el primer caracter no sea delimitador
Avanza hasta delimitador y copia el valor creando un token

y como se crean los tokens ?

Es una lista que pose esta estructura:

typedef struct s_token
{
	char			*value;
	t_token_type	type;
	int				s_before;
}	t_token;

donde value es el valor copiado en cada caso, como "||" en caso de error, necesitampos ese valor
para mostrar la misma impresion tras el error.
type, el tipo, segun la clasificacion anterior
s_before, guarda un flag para saber si existe separacion entre los tokens.

primero comprueba si el token va a estar vacio o es nulo, en ese caso lo salta.
Depues, genera el token copiando el valor de lo extraido y le asigna el tipo
añade un nuevo nodo de la lista y lo añade al final de la lista de tokens

al terminar tokenicer, ya tenemos la lista de tokens generada.
que sera la estructura que necesitara el parser.
